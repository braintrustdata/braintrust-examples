{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assistants RAG Demo\n",
        "\n",
        "This is a basic demo that uses the OpenAI assistants API to answer questions about\n",
        "Coda's help desk. It's very minimal at this point, so feel free to tweak it to your needs!\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/braintrustdata/braintrust-examples/blob/main/help-docs/py/Assistants_Help_Desk.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSB_fUHlM8gv"
      },
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY=<YOUR_OPENAI_KEY>\n",
        "%env BRAINTRUST_API_KEY=<YOUR_BRAINTRUST_KEY>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmui4miHNRKZ"
      },
      "outputs": [],
      "source": [
        "%pip install braintrust markdownify openai pydantic requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR2XzKCKRps0"
      },
      "source": [
        "# Contants\n",
        "\n",
        "Feel free to tweak these constants to scale up & down"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c33hK9cWRmug"
      },
      "outputs": [],
      "source": [
        "QA_GEN_MODEL=\"gpt-3.5-turbo\"\n",
        "ASSISTANTS_MODEL=\"gpt-4-1106-preview\"\n",
        "NUM_SECTIONS = 20\n",
        "NUM_DOCS = 20\n",
        "NUM_QUESTIONS = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odBafwulPe7U"
      },
      "source": [
        "# Download data\n",
        "\n",
        "First, let's download the data and split it into markdown sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egexell2PZ2w"
      },
      "outputs": [],
      "source": [
        "import markdownify\n",
        "import re\n",
        "import requests\n",
        "\n",
        "data = requests.get(\n",
        "    \"https://gist.githubusercontent.com/wong-codaio/b8ea0e087f800971ca5ec9eef617273e/raw/39f8bd2ebdecee485021e20f2c1d40fd649a4c77/articles.json\"\n",
        ").json()\n",
        "markdown_docs = [{\"id\": row[\"id\"], \"markdown\": markdownify.markdownify(row[\"body\"])} for row in data]\n",
        "\n",
        "i = 0\n",
        "markdown_sections = []\n",
        "for markdown_doc in markdown_docs:\n",
        "    sections = re.split(r\"(.*\\n=+\\n)\", markdown_doc[\"markdown\"])\n",
        "    current_section = \"\"\n",
        "    for section in sections:\n",
        "        if not section.strip():\n",
        "            continue\n",
        "\n",
        "        if re.match(r\".*\\n=+\\n\", section):\n",
        "            current_section = section\n",
        "        else:\n",
        "            section = current_section + section\n",
        "            markdown_sections.append({\"doc_id\": markdown_doc[\"id\"], \"section_id\": i, \"markdown\": section.strip()})\n",
        "            current_section = \"\"\n",
        "            i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99eqx0UhQCzT"
      },
      "source": [
        "# Generate QA pairs\n",
        "\n",
        "We'll iterate through several sections and generate reference QA pairs to test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxMJnuuZQ8V2"
      },
      "outputs": [],
      "source": [
        "from openai import AsyncOpenAI\n",
        "import os\n",
        "\n",
        "openai = AsyncOpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQvUTkoWNTBZ"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import json\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class QAPair(BaseModel):\n",
        "    question: str = Field(\n",
        "        ..., description=\"Question\"\n",
        "    )\n",
        "    answer: str = Field(..., description=\"Answer\")\n",
        "\n",
        "\n",
        "class QAPairs(BaseModel):\n",
        "    pairs: List[QAPair] = Field(..., description=\"List of question/answer pairs\")\n",
        "\n",
        "\n",
        "async def produce_candidate_questions(row):\n",
        "    response = await openai.chat.completions.create(\n",
        "        model=QA_GEN_MODEL,\n",
        "        messages=[{\"role\": \"assistant\", \"content\": f\"\"\"\n",
        "Please generate 8 question/answer pairs from the following text.\n",
        "\n",
        "Content:\n",
        "\n",
        "{row['markdown']}\n",
        "\"\"\"}],\n",
        "        functions=[\n",
        "            {\n",
        "                \"name\": \"propose_qa_pairs\",\n",
        "                \"description\": \"Propose some question/answer pairs for a given document\",\n",
        "                \"parameters\": QAPairs.schema(),\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    pairs = QAPairs(**json.loads(response.choices[0].message.function_call.arguments))\n",
        "    return pairs.pairs\n",
        "\n",
        "\n",
        "all_candidates_futures = [\n",
        "    asyncio.create_task(produce_candidate_questions(a)) for a in markdown_sections[:NUM_SECTIONS]\n",
        "]\n",
        "all_candidates = [await f for f in all_candidates_futures]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QTSa3g3SGYw"
      },
      "outputs": [],
      "source": [
        "all_candidates[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGXE1dnvw7IT"
      },
      "source": [
        "# Initialize the assistant, and load the files in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIB_ZfrxxLyz"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "\n",
        "tempdir = tempfile.TemporaryDirectory()\n",
        "\n",
        "markdown_files = []\n",
        "for i, d in enumerate(markdown_docs[:NUM_DOCS]):\n",
        "  fname = os.path.join(tempdir.name, f\"{i}.md\")\n",
        "  with open(fname, \"w\") as f:\n",
        "    f.write(d[\"markdown\"])\n",
        "  markdown_files.append(await openai.files.create(file=open(fname, \"rb\"), purpose=\"assistants\"))\n",
        "  print(i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf65oIZgy2Xw"
      },
      "outputs": [],
      "source": [
        "len(markdown_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBusCtKnSWbV"
      },
      "outputs": [],
      "source": [
        "assistant = await openai.beta.assistants.create(\n",
        "    name=\"Help Desk Bot\",\n",
        "    instructions=\"You are a support assistant. Answer questions from the Help Desk using the provided documents\",\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    model=ASSISTANTS_MODEL,\n",
        "    file_ids=[f.id for f in markdown_files],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkgyTiCjzm-f"
      },
      "source": [
        "Let's ask a basic question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GcJSaF8x4Q0"
      },
      "outputs": [],
      "source": [
        "all_candidates[0][0].question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXIGw67GzqqI"
      },
      "outputs": [],
      "source": [
        "thread = await openai.beta.threads.create()\n",
        "message = await openai.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=all_candidates[0][0].question,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xns2XGwhzzZx"
      },
      "outputs": [],
      "source": [
        "run = await openai.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        ")\n",
        "run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rbrd-Mx0NfU"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "while run.completed_at is None and run.failed_at is None:\n",
        "  if time.time() - start > 60:\n",
        "    print(run)\n",
        "    raise Exception(\"Run did not finish after 1 minute\")\n",
        "  run = await openai.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )\n",
        "\n",
        "print(\"Took \", time.time()-start, \" seconds to receive message\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01F9oPFT1sbP"
      },
      "outputs": [],
      "source": [
        "json.dumps(run.dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3fP1k43z490"
      },
      "outputs": [],
      "source": [
        "if run.failed_at:\n",
        "  print(\"FAIL\", run)\n",
        "else:\n",
        "  messages = await openai.beta.threads.messages.list(\n",
        "    thread_id=thread.id\n",
        "  )\n",
        "  print(messages.data[0].content[0].text.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGzxRtax3UeD"
      },
      "source": [
        "# Running an eval\n",
        "\n",
        "Now let's package this up and run an evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf-gNB3O3RsL"
      },
      "outputs": [],
      "source": [
        "from braintrust import current_span\n",
        "\n",
        "async def answer_question(input):\n",
        "  thread = await openai.beta.threads.create()\n",
        "  message = await openai.beta.threads.messages.create(\n",
        "      thread_id=thread.id,\n",
        "      role=\"user\",\n",
        "      content=input,\n",
        "  )\n",
        "  run = await openai.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        "  )\n",
        "  start = time.time()\n",
        "  while run.completed_at is None and run.failed_at is None:\n",
        "    if time.time() - start > 60:\n",
        "      print(run)\n",
        "      raise Exception(\"Run did not finish after 1 minute\")\n",
        "    run = await openai.beta.threads.runs.retrieve(\n",
        "      thread_id=thread.id,\n",
        "      run_id=run.id\n",
        "    )\n",
        "\n",
        "  current_span().log(metadata={\n",
        "      \"run\": run.dict()\n",
        "  })\n",
        "  if run.failed_at:\n",
        "    return None\n",
        "  else:\n",
        "    messages = await openai.beta.threads.messages.list(\n",
        "      thread_id=thread.id\n",
        "    )\n",
        "    return messages.data[0].content[0].text.value\n",
        "\n",
        "print(await answer_question(\"How do I create a formula?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62GMaeCD0dwO"
      },
      "outputs": [],
      "source": [
        "from autoevals import Factuality\n",
        "from braintrust import Eval\n",
        "\n",
        "def load_data():\n",
        "  return [\n",
        "      {\n",
        "          \"input\": qa_pair.question,\n",
        "          \"expected\": qa_pair.answer,\n",
        "      }\n",
        "      for section in all_candidates\n",
        "      for qa_pair in section\n",
        "  ][:NUM_QUESTIONS]\n",
        "\n",
        "await Eval(\n",
        "    \"assistants-help-desk\",\n",
        "    data=load_data,\n",
        "    task=answer_question,\n",
        "    scores=[Factuality]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
