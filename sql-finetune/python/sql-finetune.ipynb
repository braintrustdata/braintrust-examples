{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCP8uX0pyXMD"
      },
      "source": [
        "# BrainTrust Text2SQL Fine Tune Tutorial\n",
        "\n",
        "Welcome to [BrainTrust](https://www.braintrustdata.com/)! This tutorial will teach you how to finetune a `gpt-3.5-turbo` to generate SQL and evaluate it using BrainTrust compared to regular `gpt-3.5-turbo`.\n",
        "\n",
        "Before starting, please make sure that you _already_ have a BrainTrust account. If you do not, please [sign up](https://www.braintrustdata.com) or [get in touch](mailto:info@braintrustdata.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTYUb2b9yXMF"
      },
      "source": [
        "## 1. Install and setup variables\n",
        "Let's first setup our API key variables and install some dependencies."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install braintrust duckdb datasets openai pyarrow autoevals"
      ],
      "metadata": {
        "id": "Tyu2HpZTzp9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kti5t70nyXMF"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "import braintrust\n",
        "\n",
        "OPENAI_API_KEY=\"\"\n",
        "BT_API_KEY=\"\"\n",
        "openai.api_key = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pt7PHoryXMF"
      },
      "source": [
        "## 2. Define helper functions\n",
        "We'll define some helper functions that help us work with SQL related data and queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib_d5Dh7yXMF"
      },
      "outputs": [],
      "source": [
        "# Import libraries + define helper functions\n",
        "\n",
        "import duckdb\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "from Levenshtein import distance\n",
        "import openai\n",
        "import os\n",
        "import pyarrow as pa\n",
        "import time\n",
        "\n",
        "NUM_TEST_EXAMPLES = 10\n",
        "\n",
        "# Define some helper functions\n",
        "def get_table(table):\n",
        "    rows = [\n",
        "        {h: row[i] for (i, h) in enumerate(table[\"header\"])} for row in table[\"rows\"]\n",
        "    ]\n",
        "\n",
        "    return pa.Table.from_pylist(rows)\n",
        "\n",
        "AGG_OPS = [None, \"MAX\", \"MIN\", \"COUNT\", \"SUM\", \"AVG\"]\n",
        "COND_OPS = [\" ILIKE \", \">\", \"<\"]  # , \"OP\"]\n",
        "\n",
        "\n",
        "def esc_fn(s):\n",
        "    return f'''\"{s.replace('\"', '\"\"')}\"'''\n",
        "\n",
        "\n",
        "def esc_value(s):\n",
        "    if isinstance(s, str):\n",
        "        return s.replace(\"'\", \"''\")\n",
        "    else:\n",
        "        return s\n",
        "\n",
        "def codegen_query(query):\n",
        "    header = query[\"table\"][\"header\"]\n",
        "\n",
        "    projection = f\"{esc_fn(header[query['sql']['sel']])}\"\n",
        "\n",
        "    agg_op = AGG_OPS[query[\"sql\"][\"agg\"]]\n",
        "    if agg_op is not None:\n",
        "        projection = f\"{agg_op}({projection})\"\n",
        "\n",
        "    conds = query[\"sql\"][\"conds\"]\n",
        "\n",
        "    filters = \" and \".join(\n",
        "        [\n",
        "            f\"\"\"{esc_fn(header[field])}{COND_OPS[cond]}'{esc_value(value)}'\"\"\"\n",
        "            for (field, cond, value) in zip(\n",
        "                conds[\"column_index\"], conds[\"operator_index\"], conds[\"condition\"]\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    if filters:\n",
        "        filters = f\" WHERE {filters}\"\n",
        "\n",
        "    return f'SELECT {projection} FROM \"table\"{filters}'\n",
        "\n",
        "OPENAI_CACHE = None\n",
        "def openai_req(ChatCompletion=openai.ChatCompletion, **kwargs):\n",
        "    global OPENAI_CACHE\n",
        "    if OPENAI_CACHE is None:\n",
        "        os.makedirs(\"data\", exist_ok=True)\n",
        "        OPENAI_CACHE = duckdb.connect(database=\"data/oai_cache.duckdb\")\n",
        "        OPENAI_CACHE.query(\n",
        "            \"CREATE TABLE IF NOT EXISTS cache (params text, response text)\"\n",
        "        )\n",
        "\n",
        "    param_key = json.dumps(kwargs)\n",
        "    resp = OPENAI_CACHE.execute(\n",
        "        \"\"\"SELECT response FROM \"cache\" WHERE params=?\"\"\", [param_key]\n",
        "    ).fetchone()\n",
        "    if resp:\n",
        "        return json.loads(resp[0])\n",
        "\n",
        "    for i in range(5):\n",
        "      try:\n",
        "        resp = ChatCompletion.create(**kwargs).to_dict()\n",
        "        break\n",
        "      except openai.error.RateLimitError:\n",
        "        print(\"Rate limited... Sleeping for 30 seconds\")\n",
        "        time.sleep(30)\n",
        "\n",
        "\n",
        "    OPENAI_CACHE.execute(\n",
        "        \"\"\"INSERT INTO \"cache\" VALUES (?, ?)\"\"\", [param_key, json.dumps(resp)]\n",
        "    )\n",
        "\n",
        "    return resp\n",
        "\n",
        "def green(s):\n",
        "  return \"\\x1b[32m\" + s + \"\\x1b[0m\"\n",
        "\n",
        "def run_query(sql, table_record):\n",
        "    table = get_table(table_record)  # noqa\n",
        "    rel_from_arrow = duckdb.arrow(table)\n",
        "\n",
        "    result = rel_from_arrow.query(\"table\", sql).fetchone()\n",
        "    if result and len(result) > 0:\n",
        "        return result[0]\n",
        "    return None\n",
        "\n",
        "def score(r1, r2):\n",
        "    if r1 is None and r2 is None:\n",
        "        return 1\n",
        "    if r1 is None or r2 is None:\n",
        "        return 0\n",
        "\n",
        "    r1, r2 = str(r1), str(r2)\n",
        "\n",
        "    total_len = max(len(r1), len(r2))\n",
        "    return 1 - distance(r1, r2) / total_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGf_3bcqyXMG"
      },
      "source": [
        "3. ## Prepare a training set\n",
        "\n",
        "We'll use the `wikisql`[ dataset from Hugging Face](https://huggingface.co/datasets/wikisql) to create a training set of data to fine tune a model on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEd3nKbbyXMG"
      },
      "outputs": [],
      "source": [
        "# Initialize data from WikiSQL\n",
        "train_data = list(load_dataset(\"wikisql\")[\"train\"])\n",
        "\n",
        "def createTrainExample(query):\n",
        "    table = query[\"table\"]\n",
        "    rows = [\n",
        "        {h: row[i] for (i, h) in enumerate(table[\"header\"])}\n",
        "        for row in table[\"rows\"]\n",
        "    ]\n",
        "    meta = \"\\n\".join(f'\"{h}\": {[row[h] for row in rows[:10]]}' for h in table[\"header\"])\n",
        "    prompt = f\"\"\"\n",
        "    Print a SQL query (over a table named \"table\" quoted with double quotes) that answers the question below.\n",
        "\n",
        "    You have the following columns:\n",
        "    {meta}\n",
        "\n",
        "    The format should be\n",
        "    Question: the question to ask\n",
        "    SQL: the SQL to generate\n",
        "\n",
        "    Question: {query['question']}\n",
        "    SQL: \"\"\".format()\n",
        "    example = {\n",
        "        \"messages\": [\n",
        "            {\n",
        "            \"role\":\"system\",\n",
        "            \"content\":\"You are an expert at generating SQL. Respond with just SQL.\"\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "            {\"role\":\"assistant\", \"content\": codegen_query(query)}\n",
        "        ]\n",
        "    }\n",
        "    print(example)\n",
        "    return example\n",
        "\n",
        "\n",
        "createTrainExample(train_data[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnESIJDOyXMG"
      },
      "outputs": [],
      "source": [
        "# Save our training data to a file\n",
        "with open('train-sql.JSONL', mode='w', newline='') as file:\n",
        "    for i in range(100):\n",
        "        row = createTrainExample(train_data[i])\n",
        "        #add each row\n",
        "        json.dump(row, file)\n",
        "        file.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkpWfJaKyXMG"
      },
      "outputs": [],
      "source": [
        "# Upload our training data to OpenAI\n",
        "file = openai.File.create(\n",
        "  file=open(\"train-sql.JSONL\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WZJ8NaayXMG"
      },
      "source": [
        "Wait 30s to 1 minute for the file to be processed. :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgcYJc_uyXMG"
      },
      "outputs": [],
      "source": [
        "# Start a fine-tuning job\n",
        "job = openai.FineTuningJob.create(training_file=file['id'], model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r381T2YuyXMG"
      },
      "outputs": [],
      "source": [
        "# Wait for the fine-tune to complete\n",
        "FTMODELNAME = \"\"\n",
        "for i in range(100):\n",
        "    check = openai.FineTuningJob.retrieve(job['id'])\n",
        "    if (check.fine_tuned_model):\n",
        "        FTMODELNAME = check.fine_tuned_model\n",
        "        break\n",
        "    time.sleep(30)\n",
        "print(FTMODELNAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tE_1TUdyXMG"
      },
      "source": [
        "## 4. Evaluate our finetuned model\n",
        "\n",
        "Finally, we'll load in an evaluation dataset, define an evaluation function, and then compare our results with BrainTrust."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9hb2mkuyXMG"
      },
      "outputs": [],
      "source": [
        "# load in an evaluation dataset\n",
        "data = list(load_dataset(\"wikisql\")[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgRmkBSYyXMH"
      },
      "outputs": [],
      "source": [
        "# Define a generation function\n",
        "def text2sql(query, modelName):\n",
        "    table = query[\"table\"]\n",
        "    meta = \"\\n\".join(f'\"{h}\"' for h in table[\"header\"])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Print a SQL query (over a table named \"table\" quoted with double quotes) that answers the question below.\n",
        "\n",
        "You have the following columns:\n",
        "{meta}\n",
        "\n",
        "The format should be\n",
        "Question: the question to ask\n",
        "SQL: the SQL to generate\n",
        "\n",
        "Question: {query['question']}\n",
        "SQL: \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\":\"system\",\n",
        "            \"content\":\"You are an expert at generating SQL. Respond with just SQL.\"\n",
        "         },\n",
        "         {\n",
        "            \"role\":\"user\",\n",
        "            \"content\":prompt,\n",
        "         }\n",
        "    ]\n",
        "    resp = openai_req(model=modelName, messages=messages, max_tokens=1024)\n",
        "    print(resp)\n",
        "    return (\n",
        "        prompt,\n",
        "        resp,\n",
        "        resp[\"choices\"][0]['message'][\"content\"].rstrip(\";\")\n",
        "        if len(resp[\"choices\"]) > 0\n",
        "        else None,\n",
        "    )\n",
        "\n",
        "prompt, resp, _ = text2sql(data[0], FTMODELNAME)\n",
        "print(prompt + green(resp['choices'][0]['message']['content']))\n",
        "\n",
        "output_sql = resp['choices'][0]['message']['content'].rstrip(\";\")\n",
        "table = get_table(data[0]['table'])\n",
        "print(\"Correct answer:\", data[0][\"sql\"][\"human_readable\"],)\n",
        "duckdb.arrow(table).query(\"table\", output_sql)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPiKDn9UyXMH"
      },
      "outputs": [],
      "source": [
        "# Define an evaluation function\n",
        "def runEvaluation(modelName):\n",
        "    # Initialize BrainTrust experiment\n",
        "    bt = braintrust.init(project=\"text2sql-finetune\", experiment=modelName, api_key=BT_API_KEY)\n",
        "    for i in range(NUM_TEST_EXAMPLES):\n",
        "        print(f\"{i+1}/{NUM_TEST_EXAMPLES}\\r\")\n",
        "        query = data[i]\n",
        "        gt_query = codegen_query(query)\n",
        "        gt_answer = run_query(gt_query, query[\"table\"])\n",
        "\n",
        "        prompt, _, sql = text2sql(query, modelName)\n",
        "        try:\n",
        "            answer = run_query(sql, query[\"table\"])\n",
        "        except Exception as e:\n",
        "            answer = f\"FAILED: {e}\"\n",
        "\n",
        "        #Log to BrainTrust\n",
        "        bt.log(\n",
        "            inputs={\"question\": query[\"question\"]},\n",
        "            output=answer,\n",
        "            expected=gt_answer,\n",
        "            scores={\n",
        "                \"answer\": score(gt_answer, answer),\n",
        "                \"query\": score(gt_query, sql),\n",
        "            },\n",
        "            metadata={\n",
        "                \"prompt\": prompt,\n",
        "                \"gt_sql\": gt_query,\n",
        "                \"output_sql\": sql,\n",
        "                \"id\": i,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    # Print experiment results\n",
        "    print(bt.summarize())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwiF9KQEyXMH"
      },
      "outputs": [],
      "source": [
        "#Evaluate base GPT3.5-turbo\n",
        "runEvaluation(\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z25N0KKuyXMH"
      },
      "outputs": [],
      "source": [
        "# Evaluate our finetuned model\n",
        "runEvaluation(FTMODELNAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2e9cXNbyXMH"
      },
      "source": [
        "Once you run the two blocks above, you should get a link to the BrainTrust web-ui to compare the results.\n",
        "\n",
        "![results.png](results.png)\n",
        "\n",
        "We can see that finetuning significantly improved the ability of GPT-3.5-Turbo to generate SQL queries! Next, you can add more training data or maybe try improving the prompt and then evaluating with BrainTrust to assess your changes.\n",
        "\n",
        "Now, you are on your journey of building reliable AI apps with BrainTrust.\n",
        "\n",
        "Learn more on our docs @ [https://www.braintrustdata.com/docs](https://www.braintrustdata.com/docs).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_zffirXyXMH"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}